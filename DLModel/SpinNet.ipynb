{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvVOM8Bnetmg"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lfv5QLh5fZSq"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'open3d'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopen3d\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mo3d\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'open3d'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import open3d as o3d\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "L8CDBaOm02kP",
        "outputId": "80e6c218-66e6-4332-a0ba-fcdca32e609a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# import os\n",
        "# os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'  #to help with memory segmentation\n",
        "\n",
        "#Setup device aagnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Gq9Q6M9J8oP"
      },
      "source": [
        "## Utils: From script/common.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RoFkTb2sJ_qq"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "class switch(object):\n",
        "    def __init__(self, value):\n",
        "        self.value = value\n",
        "        self.fall = False\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Return the match method once, then stop\"\"\"\n",
        "        yield self.match\n",
        "        raise StopIteration\n",
        "\n",
        "    def match(self, *args):\n",
        "        \"\"\"Indicate whether or not to enter a case suite\"\"\"\n",
        "        if self.fall or not args:\n",
        "            return True\n",
        "        elif self.value in args:  # changed for v1.5, see below\n",
        "            self.fall = True\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "def s2_grid(n_alpha, n_beta):\n",
        "    '''\n",
        "    :return: rings around the equator\n",
        "    size of the kernel = n_alpha * n_beta\n",
        "    '''\n",
        "    beta = np.linspace(start=0, stop=np.pi, num=n_beta, endpoint=False) + np.pi / n_beta / 2\n",
        "    # ele = np.arcsin(np.linspace(start=0, stop=1, num=n_beta / 2, endpoint=False) + 1 / n_beta / 4)\n",
        "    # beta = np.concatenate([np.sort(-ele), ele])\n",
        "    alpha = np.linspace(start=0, stop=2 * np.pi, num=n_alpha, endpoint=False) + np.pi / n_alpha\n",
        "    B, A = np.meshgrid(beta, alpha, indexing='ij')\n",
        "    B = B.flatten()\n",
        "    A = A.flatten()\n",
        "    grid = np.stack((B, A), axis=1)\n",
        "    return grid\n",
        "\n",
        "def change_coordinates(coords, radius, p_from='C', p_to='S'):\n",
        "    \"\"\"\n",
        "    Change Spherical to Cartesian coordinates and vice versa, for points x in S^2.\n",
        "\n",
        "    In the spherical system, we have coordinates beta and alpha,\n",
        "    where beta in [0, pi] and alpha in [0, 2pi]\n",
        "\n",
        "    We use the names beta and alpha for compatibility with the SO(3) code (S^2 being a quotient SO(3)/SO(2)).\n",
        "    Many sources, like wikipedia use theta=beta and phi=alpha.\n",
        "\n",
        "    :param coords: coordinate array\n",
        "    :param p_from: 'C' for Cartesian or 'S' for spherical coordinates\n",
        "    :param p_to: 'C' for Cartesian or 'S' for spherical coordinates\n",
        "    :return: new coordinates\n",
        "    \"\"\"\n",
        "    if p_from == p_to:\n",
        "        return coords\n",
        "    elif p_from == 'S' and p_to == 'C':\n",
        "\n",
        "        beta = coords[..., 0]\n",
        "        alpha = coords[..., 1]\n",
        "        r = radius\n",
        "\n",
        "        out = np.empty(beta.shape + (3,))\n",
        "\n",
        "        ct = np.cos(beta)\n",
        "        cp = np.cos(alpha)\n",
        "        st = np.sin(beta)\n",
        "        sp = np.sin(alpha)\n",
        "        out[..., 0] = r * st * cp  # x\n",
        "        out[..., 1] = r * st * sp  # y\n",
        "        out[..., 2] = r * ct  # z\n",
        "        return out\n",
        "\n",
        "    elif p_from == 'C' and p_to == 'S':\n",
        "\n",
        "        x = coords[..., 0]\n",
        "        y = coords[..., 1]\n",
        "        z = coords[..., 2]\n",
        "\n",
        "        out = np.empty(x.shape + (2,))\n",
        "        out[..., 0] = np.arccos(z)  # beta\n",
        "        out[..., 1] = np.arctan2(y, x)  # alpha\n",
        "        return out\n",
        "\n",
        "    else:\n",
        "        raise ValueError('Unknown conversion:' + str(p_from) + ' to ' + str(p_to))\n",
        "\n",
        "def get_voxel_coordinate(radius, rad_n, azi_n, ele_n):\n",
        "    grid = s2_grid(n_alpha=azi_n, n_beta=ele_n)\n",
        "    pts_xyz_on_S2 = change_coordinates(grid, radius, 'S', 'C')\n",
        "    pts_xyz_on_S2 = np.expand_dims(pts_xyz_on_S2, axis=0).repeat(rad_n, axis=0)\n",
        "    scale = np.reshape(np.arange(rad_n) / rad_n + 1 / (2 * rad_n), [rad_n, 1, 1])\n",
        "    pts_xyz = scale * pts_xyz_on_S2\n",
        "    return pts_xyz\n",
        "\n",
        "def angles2rotation_matrix(angles):\n",
        "    Rx = np.array([[1, 0, 0],\n",
        "                   [0, np.cos(angles[0]), -np.sin(angles[0])],\n",
        "                   [0, np.sin(angles[0]), np.cos(angles[0])]])\n",
        "    Ry = np.array([[np.cos(angles[1]), 0, np.sin(angles[1])],\n",
        "                   [0, 1, 0],\n",
        "                   [-np.sin(angles[1]), 0, np.cos(angles[1])]])\n",
        "    Rz = np.array([[np.cos(angles[2]), -np.sin(angles[2]), 0],\n",
        "                   [np.sin(angles[2]), np.cos(angles[2]), 0],\n",
        "                   [0, 0, 1]])\n",
        "    R = np.dot(Rz, np.dot(Ry, Rx))\n",
        "    return R\n",
        "\n",
        "def pad_image(input, kernel_size):\n",
        "    \"\"\"\n",
        "    Circularly padding image for convolution\n",
        "    :param input: [B, C, H, W]\n",
        "    :param kernel_size:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    device = input.device\n",
        "    if kernel_size % 2 == 0:\n",
        "        pad_size = kernel_size // 2\n",
        "        output = torch.cat([input, input[:, :, :, 0:pad_size]], dim=3)\n",
        "        zeros_pad = torch.zeros([output.shape[0], output.shape[1], pad_size, output.shape[3]]).to(device)\n",
        "        output = torch.cat([output, zeros_pad], dim=2)\n",
        "    else:\n",
        "        pad_size = (kernel_size - 1) // 2\n",
        "        output = torch.cat([input, input[:, :, :, 0:pad_size]], dim=3)\n",
        "        output = torch.cat([input[:, :, :, -pad_size:], output], dim=3)\n",
        "        zeros_pad = torch.zeros([output.shape[0], output.shape[1], pad_size, output.shape[3]]).to(device)\n",
        "        output = torch.cat([output, zeros_pad], dim=2)\n",
        "        output = torch.cat([zeros_pad, output], dim=2)\n",
        "    return output\n",
        "\n",
        "def pad_image_3d(input, kernel_size):\n",
        "    \"\"\"\n",
        "    Circularly padding image for convolution\n",
        "    :param input: [B, C, D, H, W]\n",
        "    :param kernel_size:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    device = input.device\n",
        "    if kernel_size % 2 == 0:\n",
        "        pad_size = kernel_size // 2\n",
        "        output = torch.cat([input, input[:, :, :, :, 0:pad_size]], dim=4)\n",
        "        zeros_pad = torch.zeros([output.shape[0], output.shape[1], output.shape[2], pad_size, output.shape[4]]).to(\n",
        "            device)\n",
        "        output = torch.cat([output, zeros_pad], dim=3)\n",
        "    else:\n",
        "        pad_size = (kernel_size - 1) // 2\n",
        "        output = torch.cat([input, input[:, :, :, :, 0:pad_size]], dim=4)\n",
        "        output = torch.cat([input[:, :, :, :, -pad_size:], output], dim=4)\n",
        "        zeros_pad = torch.zeros([output.shape[0], output.shape[1], output.shape[2], pad_size, output.shape[4]]).to(\n",
        "            device)\n",
        "        output = torch.cat([output, zeros_pad], dim=3)\n",
        "        output = torch.cat([zeros_pad, output], dim=3)\n",
        "    return output\n",
        "\n",
        "def var_to_invar(pts, rad_n, azi_n, ele_n):\n",
        "    \"\"\"\n",
        "    :param pts: input points data, [B, N, nsample, 3]\n",
        "    :param rad_n: radial number\n",
        "    :param azi_n: azimuth number\n",
        "    :param ele_n: elevator number\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    device = pts.device\n",
        "    B, N, nsample, C = pts.shape\n",
        "    assert N == rad_n * azi_n * ele_n\n",
        "    angle_step = np.array([0, 0, 2 * np.pi / azi_n])\n",
        "    pts = pts.view(B, rad_n, ele_n, azi_n, nsample, C)\n",
        "\n",
        "    R = np.zeros([azi_n, 3, 3])\n",
        "    for i in range(azi_n):\n",
        "        angle = -1 * i * angle_step\n",
        "        r = angles2rotation_matrix(angle)\n",
        "        R[i] = r\n",
        "    R = torch.FloatTensor(R).to(device)\n",
        "    R = R.view(1, 1, 1, azi_n, 3, 3).repeat(B, rad_n, ele_n, 1, 1, 1)\n",
        "    new_pts = torch.matmul(pts, R.transpose(-1, -2))\n",
        "\n",
        "    del R\n",
        "    del pts\n",
        "\n",
        "    return new_pts.view(B, -1, nsample, C)\n",
        "\n",
        "import numpy as np\n",
        "from scipy.spatial import cKDTree\n",
        "\n",
        "def ball_query(pts, new_pts, radius, nsample):\n",
        "    \"\"\"\n",
        "    :param pts: all points, [B, N, 3]\n",
        "    :param new_pts: query points, [B, S, 3]\n",
        "    :param radius: local spherical radius\n",
        "    :param nsample: max sample number in local sphere\n",
        "    :return: indices of sampled points around new_pts [B, S, nsample]\n",
        "    \"\"\"\n",
        "    device = pts.device\n",
        "    B, N, C = pts.shape\n",
        "    _, S, _ = new_pts.shape\n",
        "\n",
        "    # Create an empty tensor to hold the indices of sampled points\n",
        "    sampled_indices = torch.zeros(B, S, nsample, dtype=torch.long, device=device)\n",
        "\n",
        "    for b in range(B):\n",
        "        # Calculate pairwise distances between all points and query points\n",
        "        pts_b = pts[b]  # [N, 3]\n",
        "        new_pts_b = new_pts[b]  # [S, 3]\n",
        "\n",
        "        # Expand dimensions for broadcasting\n",
        "        pts_exp = pts_b.unsqueeze(0)  # [1, N, 3]\n",
        "        new_pts_exp = new_pts_b.unsqueeze(1)  # [S, 1, 3]\n",
        "\n",
        "        # Compute squared distances\n",
        "        dists_sq = torch.sum((pts_exp - new_pts_exp) ** 2, dim=-1)  # [S, N]\n",
        "\n",
        "        # Find points within the radius\n",
        "        mask = dists_sq <= radius ** 2\n",
        "        for s in range(S):\n",
        "            indices = torch.nonzero(mask[s]).squeeze(1)  # [num_points_in_sphere]\n",
        "\n",
        "            if indices.numel() > nsample:\n",
        "                # If there are more points than nsample, randomly sample\n",
        "                indices = indices[torch.randperm(indices.size(0))[:nsample]]\n",
        "            elif indices.numel() < nsample:\n",
        "                # If there are fewer points than nsample, pad with zeros if indices is empty\n",
        "                pad_size = nsample - indices.numel()\n",
        "                if pad_size > 0:\n",
        "                    if indices.numel() == 0:\n",
        "                        # No points found, pad with zeros (or any other placeholder index like -1)\n",
        "                        indices = torch.zeros(nsample, dtype=torch.long, device=device)\n",
        "                    else:\n",
        "                        # Repeat the last index to fill remaining spots\n",
        "                        indices = torch.cat([indices, indices[-1].repeat(pad_size)])\n",
        "\n",
        "            # Store the indices of the sampled points\n",
        "            sampled_indices[b, s, :indices.numel()] = indices\n",
        "\n",
        "    return sampled_indices\n",
        "\n",
        "def grouping_operation(features, idx):\n",
        "    \"\"\"\n",
        "    Agrupa características basadas en índices.\n",
        "\n",
        "    :param features: Tensor de características con forma (B, C, N)\n",
        "    :param idx: Tensor de índices con forma (B, npoint, nsample)\n",
        "    :return: Tensor de características agrupadas con forma (B, C, npoint, nsample)\n",
        "    \"\"\"\n",
        "    B, C, N = features.shape\n",
        "    _, npoint, nsample = idx.shape\n",
        "\n",
        "    # Expande 'idx' para que coincida con la forma de 'features'\n",
        "    idx_expanded = idx.unsqueeze(1)  # Forma (B, 1, npoint, nsample)\n",
        "\n",
        "    # Ajustar 'features' para usar 'torch.gather'\n",
        "    features_expanded = features.unsqueeze(2).expand(-1, -1, npoint, -1)  # Forma (B, C, npoint, N)\n",
        "\n",
        "    # Agrupa características usando los índices expandidos\n",
        "    grouped_features = torch.gather(features_expanded, 3, idx_expanded)\n",
        "\n",
        "    return grouped_features\n",
        "\n",
        "def sphere_query(pts, new_pts, radius, nsample):\n",
        "  \"\"\"\n",
        "  :param pts: all points, [B. N. 3]\n",
        "  :param new_pts: query points, [B, S. 3]\n",
        "  :param radius: local sperical radius\n",
        "  :param nsample: max sample number in local sphere\n",
        "  :return:\n",
        "  \"\"\"\n",
        "\n",
        "  device = pts.device\n",
        "  B, N, C = pts.shape\n",
        "  _, S, _ = new_pts.shape\n",
        "\n",
        "  pts = pts.contiguous()\n",
        "  new_pts = new_pts.contiguous()\n",
        "  group_idx = ball_query(pts, new_pts, radius, nsample)\n",
        "  #print(group_idx)\n",
        "  #group_idx = pnt2.ball_query(radius, nsample, pts, new_pts)\n",
        "  mask = group_idx[:, :, 0].unsqueeze(2).repeat(1, 1, nsample)\n",
        "  mask = (group_idx == mask).float()\n",
        "  mask[:, :, 0] = 0\n",
        "\n",
        "  # C implementation\n",
        "  pts_trans = pts.transpose(1, 2).contiguous()\n",
        "  #new_points = pnt2.grouping_operation(pts_trans, group_idx)  # (B, 3, npoint, nsample)\n",
        "  new_points = grouping_operation(pts_trans, group_idx)  # (B, 3, npoint, nsample)\n",
        "  new_points = new_points.permute([0, 2, 3, 1])\n",
        "\n",
        "  # replace the wrong points using new_pts\n",
        "  mask = mask.unsqueeze(3).repeat([1, 1, 1, 3])\n",
        "  # new_pts = new_pts.unsqueeze(2).repeat([1, 1, nsample + 1, 1])\n",
        "  new_pts = new_pts.unsqueeze(2).repeat([1, 1, nsample, 1])\n",
        "  n_points = new_points * (1 - mask).float() + new_pts * mask.float()\n",
        "\n",
        "  del mask\n",
        "  del new_points\n",
        "  del group_idx\n",
        "  del new_pts\n",
        "  del pts\n",
        "  del pts_trans\n",
        "\n",
        "  return n_points\n",
        "\n",
        "def l2_norm(input, axis=1):\n",
        "    norm = torch.norm(input, p=2, dim=axis, keepdim=True)\n",
        "    output = torch.div(input, norm)\n",
        "    return output\n",
        "\n",
        "def cal_Z_axis(local_cor, local_weight=None, ref_point=None):\n",
        "    device = local_cor.device\n",
        "    B, N, _ = local_cor.shape\n",
        "    cov_matrix = torch.matmul(local_cor.transpose(-1, -2), local_cor) if local_weight is None \\\n",
        "        else Variable(torch.matmul(local_cor.transpose(-1, -2), local_cor * local_weight), requires_grad=True)\n",
        "    #Z_axis = torch.symeig(cov_matrix, eigenvectors=True)[1][:, :, 0]\n",
        "    Z_axis = torch.linalg.eigh(cov_matrix, UPLO=\"U\")[1][:, :, 0]\n",
        "    mask = (torch.sum(-Z_axis * ref_point, dim=1) < 0).float().unsqueeze(1)\n",
        "    Z_axis = Z_axis * (1 - mask) - Z_axis * mask\n",
        "\n",
        "    return Z_axis\n",
        "\n",
        "def RodsRotatFormula(a, b):\n",
        "    B, _ = a.shape\n",
        "    device = a.device\n",
        "    b = b.to(device)\n",
        "    c = torch.cross(a, b)\n",
        "    theta = torch.acos(F.cosine_similarity(a, b)).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "    c = F.normalize(c, p=2, dim=1)\n",
        "    one = torch.ones(B, 1, 1).to(device)\n",
        "    zero = torch.zeros(B, 1, 1).to(device)\n",
        "    a11 = zero\n",
        "    a12 = -c[:, 2].unsqueeze(1).unsqueeze(2)\n",
        "    a13 = c[:, 1].unsqueeze(1).unsqueeze(2)\n",
        "    a21 = c[:, 2].unsqueeze(1).unsqueeze(2)\n",
        "    a22 = zero\n",
        "    a23 = -c[:, 0].unsqueeze(1).unsqueeze(2)\n",
        "    a31 = -c[:, 1].unsqueeze(1).unsqueeze(2)\n",
        "    a32 = c[:, 0].unsqueeze(1).unsqueeze(2)\n",
        "    a33 = zero\n",
        "    Rx = torch.cat(\n",
        "        (torch.cat((a11, a12, a13), dim=2), torch.cat((a21, a22, a23), dim=2), torch.cat((a31, a32, a33), dim=2)),\n",
        "        dim=1)\n",
        "    I = torch.eye(3).to(device)\n",
        "    R = I.unsqueeze(0).repeat(B, 1, 1) + torch.sin(theta) * Rx + (1 - torch.cos(theta)) * torch.matmul(Rx, Rx)\n",
        "    return R.transpose(-1, -2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgYHntgEe5eR"
      },
      "source": [
        "# Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyeOjpX2kkaM"
      },
      "source": [
        "## From network/threeDCCN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2lqBAkBe6reS"
      },
      "outputs": [],
      "source": [
        "import pdb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# import script.common as cm\n",
        "\n",
        "\n",
        "class BaseNet(nn.Module):\n",
        "    \"\"\" Takes a list of images as input, and returns for each image:\n",
        "        - a pixelwise descriptor\n",
        "        - a pixelwise confidence\n",
        "    \"\"\"\n",
        "\n",
        "    def forward_one(self, x):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def forward(self, imgs):\n",
        "        res = self.forward_one(imgs)\n",
        "        return res\n",
        "\n",
        "\n",
        "class Cyclindrical_ConvNet(BaseNet):\n",
        "    def __init__(self, inchan=3, dilated=True, dilation=1, bn=True, bn_affine=False):\n",
        "        BaseNet.__init__(self)\n",
        "        self.inchan = inchan\n",
        "        self.curchan = inchan\n",
        "        self.dilated = dilated\n",
        "        self.dilation = dilation\n",
        "        self.bn = bn\n",
        "        self.bn_affine = bn_affine\n",
        "        self.ops = nn.ModuleList([])\n",
        "\n",
        "    def _make_bn_2d(self, outd):\n",
        "        return nn.BatchNorm2d(outd, affine=self.bn_affine)\n",
        "\n",
        "    def _make_bn_3d(self, outd):\n",
        "        return nn.BatchNorm3d(outd, affine=self.bn_affine)\n",
        "\n",
        "    def _add_conv_2d(self, outd, k=3, stride=1, dilation=1, bn=True, relu=True):\n",
        "        d = self.dilation * dilation\n",
        "        self.dilation *= stride\n",
        "        self.ops.append(nn.Conv2d(self.curchan, outd, kernel_size=(k, k), dilation=d))\n",
        "        if bn and self.bn: self.ops.append(self._make_bn_2d(outd))\n",
        "        if relu: self.ops.append(nn.ReLU(inplace=True))\n",
        "        self.curchan = outd\n",
        "\n",
        "    def _add_conv_3d(self, outd, k, stride=1, dilation=1, bn=True, relu=True):\n",
        "        d = self.dilation * dilation\n",
        "        self.dilation *= stride\n",
        "        self.ops.append(nn.Conv3d(self.curchan, outd, kernel_size=(k[0], k[1], k[2]), dilation=d))\n",
        "        if bn and self.bn: self.ops.append(self._make_bn_3d(outd))\n",
        "        if relu: self.ops.append(nn.ReLU(inplace=True))\n",
        "        self.curchan = outd\n",
        "\n",
        "    def forward_one(self, x):\n",
        "        assert self.ops, \"You need to add convolutions first\"\n",
        "        for n, op in enumerate(self.ops):\n",
        "            k_exist = hasattr(op, 'kernel_size')\n",
        "            if k_exist:\n",
        "                if len(op.kernel_size) == 3:\n",
        "                    x = pad_image_3d(x, op.kernel_size[1] + (op.kernel_size[1] - 1) * (op.dilation[0] - 1))\n",
        "                else:\n",
        "                    if len(x.shape) == 5:\n",
        "                        x = x.squeeze(2)\n",
        "                    x = pad_image(x, op.kernel_size[0] + (op.kernel_size[0] - 1) * (op.dilation[0] - 1))\n",
        "            x = op(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Cylindrical_Net(Cyclindrical_ConvNet):\n",
        "    \"\"\" Compute a descriptor for all overlapping patches.\n",
        "        From the L2Net paper (CVPR'17).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, inchan=16, dim=32, **kw):\n",
        "        Cyclindrical_ConvNet.__init__(self, inchan=inchan, **kw)\n",
        "        add_conv_2d = lambda n, **kw: self._add_conv_2d(n, **kw)\n",
        "        add_conv_3d = lambda n, **kw: self._add_conv_3d(n, **kw)\n",
        "        add_conv_3d(32, k=[3, 3, 3])\n",
        "        add_conv_3d(32, k=[3, 3, 3])\n",
        "        add_conv_3d(64, k=[3, 3, 3])\n",
        "        add_conv_3d(64, k=[3, 3, 3])\n",
        "        add_conv_2d(128, stride=2)\n",
        "        add_conv_2d(128)\n",
        "        add_conv_2d(64, stride=2)\n",
        "        add_conv_2d(64)\n",
        "        add_conv_2d(32, k=2, stride=2, relu=False)\n",
        "        add_conv_2d(32, k=2, stride=2, relu=False)\n",
        "        add_conv_2d(dim, k=2, stride=2, bn=False, relu=False)\n",
        "        self.out_dim = dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6Pg9SyYNkM4"
      },
      "source": [
        "## From network/SpinNet\n",
        "\n",
        "A descriptor is a representation that captures distinctive features or characteristics of points in a point cloud.\n",
        "\n",
        "In point cloud registration, descriptors are used to identify and match corresponding points between different point clouds\n",
        "\n",
        "In deep learning, descriptors are typically learned features that capture high-level patterns or representations from raw point cloud data. These descriptors are often produced by neural network models and can be used for various tasks such as classification, segmentation, and registration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mCJxhnTG3kqJ"
      },
      "outputs": [],
      "source": [
        "class Descriptor_Net(nn.Module):\n",
        "    def __init__(self, des_r, rad_n, azi_n, ele_n, voxel_r, voxel_sample, dataset):\n",
        "        super(Descriptor_Net, self).__init__()\n",
        "        self.des_r = des_r\n",
        "        self.rad_n = rad_n\n",
        "        self.azi_n = azi_n\n",
        "        self.ele_n = ele_n\n",
        "        self.voxel_r = voxel_r\n",
        "        self.voxel_sample = voxel_sample\n",
        "        self.dataset = dataset\n",
        "\n",
        "        self.bn_xyz_raising = nn.BatchNorm2d(16)\n",
        "        self.bn_mapping = nn.BatchNorm2d(16)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.xyz_raising = nn.Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.conv_net = Cylindrical_Net(inchan=16, dim=32)\n",
        "\n",
        "    def forward(self, input):\n",
        "        center = input[:, -1, :].unsqueeze(1)\n",
        "        delta_x = input[:, :, 0:3] - center[:, :, 0:3]  # (B, npoint, 3), normalized coordinates\n",
        "        for case in switch(self.dataset):\n",
        "            if case('3DMatch'):\n",
        "                z_axis = cal_Z_axis(delta_x, ref_point=input[:, -1, :3])\n",
        "                z_axis = l2_norm(z_axis, axis=1)\n",
        "                R = RodsRotatFormula(z_axis, torch.FloatTensor([0, 0, 1]).unsqueeze(0).repeat(z_axis.shape[0], 1))\n",
        "                delta_x = torch.matmul(delta_x, R)\n",
        "                break\n",
        "            if case('KITTI'):\n",
        "                break\n",
        "\n",
        "        # partition the local surface along elevator, azimuth, radial dimensions\n",
        "        S2_xyz = torch.FloatTensor(get_voxel_coordinate(radius=self.des_r,\n",
        "                                                           rad_n=self.rad_n,\n",
        "                                                           azi_n=self.azi_n,\n",
        "                                                           ele_n=self.ele_n))\n",
        "\n",
        "        pts_xyz = S2_xyz.view(1, -1, 3).repeat([delta_x.shape[0], 1, 1]).to(device)  #.cuda()\n",
        "        # query points in sphere\n",
        "        new_points = sphere_query(delta_x, pts_xyz, radius=self.voxel_r,\n",
        "                                     nsample=self.voxel_sample)\n",
        "        # transform rotation-variant coords into rotation-invariant coords\n",
        "        new_points = new_points - pts_xyz.unsqueeze(2).repeat([1, 1, self.voxel_sample, 1])\n",
        "        new_points = var_to_invar(new_points, self.rad_n, self.azi_n, self.ele_n)\n",
        "\n",
        "        new_points = new_points.permute(0, 3, 1, 2)  # (B, C_in, npoint, nsample), input features\n",
        "        C_in = new_points.size()[1]\n",
        "        nsample = new_points.size()[3]\n",
        "        x = self.activation(self.bn_xyz_raising(self.xyz_raising(new_points)))\n",
        "        x = F.max_pool2d(x, kernel_size=(1, nsample)).squeeze(3)  # (B, C_in, npoint)\n",
        "        del new_points\n",
        "        del pts_xyz\n",
        "        x = x.view(x.shape[0], x.shape[1], self.rad_n, self.ele_n, self.azi_n)\n",
        "\n",
        "        x = self.conv_net(x)\n",
        "        x = F.max_pool2d(x, kernel_size=(x.shape[2], x.shape[3]))\n",
        "\n",
        "        return x\n",
        "\n",
        "    def get_parameter(self):\n",
        "        return list(self.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6GoGKz-gW5P"
      },
      "source": [
        "# Load pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HF1Eguf95WwL"
      },
      "outputs": [],
      "source": [
        "model = Descriptor_Net(0.30, 9, 80, 40, 0.04, 30, '3DMatch')\n",
        "model = nn.DataParallel(model, device_ids=[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9og3b_KnGBSy",
        "outputId": "626ef449-ae1f-4d23-d7b1-46c17b62ee69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filename = \"./PreTrainedModels/3DMatch_best.pkl\"\n",
        "model.load_state_dict(torch.load(filename, weights_only=False, map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGMPEcoskKcB",
        "outputId": "7a3478ee-3a4f-43b1-9dd2-758cc65af784"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataParallel(\n",
              "  (module): Descriptor_Net(\n",
              "    (bn_xyz_raising): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn_mapping): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (activation): ReLU()\n",
              "    (xyz_raising): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (conv_net): Cylindrical_Net(\n",
              "      (ops): ModuleList(\n",
              "        (0): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
              "        (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
              "        (4): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "        (6): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
              "        (7): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
              "        (8): ReLU(inplace=True)\n",
              "        (9): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
              "        (10): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
              "        (11): ReLU(inplace=True)\n",
              "        (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "        (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
              "        (14): ReLU(inplace=True)\n",
              "        (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
              "        (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
              "        (17): ReLU(inplace=True)\n",
              "        (18): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
              "        (19): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
              "        (20): ReLU(inplace=True)\n",
              "        (21): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4))\n",
              "        (22): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
              "        (23): ReLU(inplace=True)\n",
              "        (24): Conv2d(64, 32, kernel_size=(2, 2), stride=(1, 1), dilation=(4, 4))\n",
              "        (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
              "        (26): Conv2d(32, 32, kernel_size=(2, 2), stride=(1, 1), dilation=(8, 8))\n",
              "        (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
              "        (28): Conv2d(32, 32, kernel_size=(2, 2), stride=(1, 1), dilation=(16, 16))\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mjj_-v4HDimF"
      },
      "source": [
        "# Getting Data Ready\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eAcrJxEhqyW"
      },
      "source": [
        "## Import Data: From 3DMatch/intermediate-files-real/7-scenes-redkitchen\n",
        "\n",
        "Extract tar file, only using 1 scene: 7-scenes-redkitchen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b66ipBVgJcG2"
      },
      "source": [
        "## From ThreeDMatch/Test/tools.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NQxZQiFCJbYh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def get_pcd(pcdpath, filename):\n",
        "    return o3d.io.read_point_cloud(os.path.join(pcdpath, filename + '.ply'))\n",
        "\n",
        "def get_keypts(keyptspath, filename):\n",
        "    keypts = np.fromfile(os.path.join(keyptspath, filename + '.keypts.bin'), dtype=np.float32)\n",
        "    num_keypts = int(keypts[0])\n",
        "    keypts = keypts[1:].reshape([num_keypts, 3])\n",
        "    return keypts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_qgPLRPJQ-m"
      },
      "source": [
        "## From ThreeDMatch/Test/preparation.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MUX1zOvIHc3V"
      },
      "outputs": [],
      "source": [
        "import open3d\n",
        "import time\n",
        "from sklearn.neighbors import KDTree\n",
        "\n",
        "def make_open3d_point_cloud(xyz, color=None):\n",
        "    pcd = open3d.geometry.PointCloud()\n",
        "    pcd.points = open3d.utility.Vector3dVector(xyz)\n",
        "    if color is not None:\n",
        "        pcd.paint_uniform_color(color)\n",
        "    return pcd\n",
        "\n",
        "def build_patch_input(pcd, keypts, vicinity=0.3, num_points_per_patch=2048):\n",
        "    refer_pts = keypts.astype(np.float32)\n",
        "    pts = np.array(pcd.points).astype(np.float32)\n",
        "    num_patches = refer_pts.shape[0]\n",
        "    tree = KDTree(pts[:, 0:3])\n",
        "    ind_local = tree.query_radius(refer_pts[:, 0:3], r=vicinity)\n",
        "    local_patches = np.zeros([num_patches, num_points_per_patch, 3], dtype=float)\n",
        "    for i in range(num_patches):\n",
        "        local_neighbors = pts[ind_local[i], :]\n",
        "        if local_neighbors.shape[0] >= num_points_per_patch:\n",
        "            temp = np.random.choice(range(local_neighbors.shape[0]), num_points_per_patch, replace=False)\n",
        "            local_neighbors = local_neighbors[temp]\n",
        "            local_neighbors[-1, :] = refer_pts[i, :]\n",
        "        else:\n",
        "            fix_idx = np.asarray(range(local_neighbors.shape[0]))\n",
        "            while local_neighbors.shape[0] + fix_idx.shape[0] < num_points_per_patch:\n",
        "                fix_idx = np.concatenate((fix_idx, np.asarray(range(local_neighbors.shape[0]))), axis=0)\n",
        "            random_idx = np.random.choice(local_neighbors.shape[0], num_points_per_patch - fix_idx.shape[0],\n",
        "                                          replace=False)\n",
        "            choice_idx = np.concatenate((fix_idx, random_idx), axis=0)\n",
        "            local_neighbors = local_neighbors[choice_idx]\n",
        "            local_neighbors[-1, :] = refer_pts[i, :]\n",
        "        local_patches[i] = local_neighbors\n",
        "\n",
        "    return local_patches\n",
        "\n",
        "def prepare_patch(pcdpath, filename, keyptspath, trans_matrix):\n",
        "    pcd = get_pcd(pcdpath, filename)\n",
        "    keypts = get_keypts(keyptspath, filename)\n",
        "    # load D3Feat keypts\n",
        "    if is_D3Feat_keypts:\n",
        "        keypts_path = './D3Feat_contralo-54-pred/keypoints/' + pcdpath.split('/')[-2] + '/' + filename + '.npy'\n",
        "        keypts = np.load(keypts_path)\n",
        "        keypts = keypts[-5000:, :]\n",
        "    if is_rotate_dataset:\n",
        "        # Add arbitrary rotation\n",
        "        # rotate terminal frament with an arbitrary angle around the z-axis\n",
        "        angles_3d = np.random.rand(3) * np.pi * 2\n",
        "        R = angles2rotation_matrix(angles_3d)\n",
        "        T = np.identity(4)\n",
        "        T[:3, :3] = R\n",
        "        pcd.transform(T)\n",
        "        keypts_pcd = make_open3d_point_cloud(keypts)\n",
        "        keypts_pcd.transform(T)\n",
        "        keypts = np.array(keypts_pcd.points)\n",
        "        trans_matrix.append(T)\n",
        "\n",
        "    local_patches = build_patch_input(pcd, keypts)  # [num_keypts, 1024, 4]\n",
        "    return local_patches\n",
        "\n",
        "def generate_descriptor(model, desc_name, pcdpath, keyptspath, descpath):\n",
        "  model.eval()\n",
        "  num_frag = len(os.listdir(pcdpath))\n",
        "  num_desc = len(os.listdir(descpath))\n",
        "  trans_matrix = []\n",
        "  if num_frag == num_desc:\n",
        "    print(\"Descriptor already prepared.\")\n",
        "    return\n",
        "  for j in range(num_frag):\n",
        "      local_patches = prepare_patch(pcdpath, 'cloud_bin_' + str(j), keyptspath, trans_matrix)\n",
        "      input_ = torch.tensor(local_patches.astype(np.float32)).to(device)\n",
        "      B = input_.shape[0]\n",
        "      input_ = input_.to(device)\n",
        "      model = model.to(device)\n",
        "      #input_ = input_.cuda()\n",
        "      #model = model.cuda()\n",
        "      # calculate descriptors\n",
        "      desc_list = []\n",
        "      start_time = time.time()\n",
        "      desc_len = 32\n",
        "      step_size = 10 #100\n",
        "      iter_num = int(np.ceil(B / step_size))\n",
        "      for k in range(iter_num):\n",
        "          if k %10 == 0:\n",
        "            print(f\"{k}/{iter_num}\")\n",
        "          if k == iter_num - 1:\n",
        "              desc = model(input_[k * step_size:, :, :])\n",
        "          else:\n",
        "              desc = model(input_[k * step_size: (k + 1) * step_size, :, :])\n",
        "          if desc == None:\n",
        "              print(\"se despichó Tere\", k)\n",
        "          desc_list.append(desc.view(desc.shape[0], desc_len).detach().cpu().numpy())\n",
        "          del desc\n",
        "      step_time = time.time() - start_time\n",
        "      print(f'Finish {B} descriptors spend {step_time:.4f}s')\n",
        "      #print(descpath + 'cloud_bin_' + str(j) + f\".desc.{desc_name}.bin\") #!Extra\n",
        "      desc = np.concatenate(desc_list, 0).reshape([B, desc_len])\n",
        "      np.save(descpath + 'cloud_bin_' + str(j) + f\".desc.{desc_name}.bin\", desc.astype(np.float32))\n",
        "  if is_rotate_dataset:\n",
        "      scene_name = pcdpath.split('/')[-2]\n",
        "      all_trans_matrix[scene_name] = trans_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJTh90RX3L7J",
        "outputId": "5b68ce4c-b179-4f7e-d69b-b9b876f48771"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Begin Processing 7-scenes-redkitchen\n",
            "0/500\n",
            "Finish 5000 descriptors spend 10.3766s\n",
            "SpinNet_desc_09130852/7-scenes-redkitchen/cloud_bin_0.desc.SpinNet.bin\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 320 into shape (5000,32)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[14], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBegin Processing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscene\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m   \u001b[38;5;66;03m#torch.cuda.empty_cache()\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m   \u001b[43mgenerate_descriptor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSpinNet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpcdpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpcdpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeyptspath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeyptspath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinish in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_rotate_dataset:\n",
            "Cell \u001b[1;32mIn[13], line 98\u001b[0m, in \u001b[0;36mgenerate_descriptor\u001b[1;34m(model, desc_name, pcdpath, keyptspath, descpath)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinish \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mB\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m descriptors spend \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28mprint\u001b[39m(descpath \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcloud_bin_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(j) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.desc.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdesc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.bin\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m#!Extra\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m     desc \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdesc_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc_len\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m     np\u001b[38;5;241m.\u001b[39msave(descpath \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcloud_bin_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(j) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.desc.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdesc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.bin\u001b[39m\u001b[38;5;124m\"\u001b[39m, desc\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_rotate_dataset:\n",
            "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 320 into shape (5000,32)"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "experiment_id = time.strftime('%m%d%H%M')\n",
        "model_str = experiment_id\n",
        "if not os.path.exists(f\"SpinNet_desc_{model_str}/\"):\n",
        "        os.mkdir(f\"SpinNet_desc_{model_str}\")\n",
        "\n",
        "scene_list = ['7-scenes-redkitchen']\n",
        "\n",
        "all_trans_matrix = {}\n",
        "is_rotate_dataset = False\n",
        "is_D3Feat_keypts = False\n",
        "for scene in scene_list:\n",
        "  pcdpath = f'./Data/3DMatch/fragments/{scene}/'\n",
        "  interpath = f'./Data/3DMatch/intermediate-files-real/{scene}/'\n",
        "  keyptspath = interpath\n",
        "  descpath = os.path.join(\"\", f\"SpinNet_desc_{model_str}/{scene}/\")\n",
        "  if not os.path.exists(descpath):\n",
        "    os.makedirs(descpath)\n",
        "\n",
        "  start_time = time.time()\n",
        "  print(f\"Begin Processing {scene}\")\n",
        "  #torch.cuda.empty_cache()\n",
        "  generate_descriptor(model, desc_name='SpinNet', pcdpath=pcdpath, keyptspath=keyptspath, descpath=descpath)\n",
        "  print(f\"Finish in {time.time() - start_time}s\")\n",
        "if is_rotate_dataset:\n",
        "    np.save(f\"trans_matrix\", all_trans_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Acabó pero no se guardó el archivo, tampoco tiró error\n",
        "revisar si el np.save está sirviendo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "desc = np.array([1,2,3])\n",
        "np.save(\"SpinNet_desc_09130852/7-scenes-redkitchen/cloud_bin_0.desc.SpinNet.bin\", desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
